{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4e85a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded keys: ['BTCUSDT_1h_5year', 'ETHUSDT_1m_5year', 'BTCUSDT_5m_5year', 'BTCUSDT_15m_5year', 'ETHUSDT_1h_5year', 'BTCUSDT_1m_5year', 'ETHUSDT_5m_5year', 'ETHUSDT_15m_5year']\n",
      "\n",
      "Sample head for BTCUSDT_5m_5year:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-05 11:10:00</td>\n",
       "      <td>9042.40</td>\n",
       "      <td>9044.94</td>\n",
       "      <td>9036.61</td>\n",
       "      <td>9041.88</td>\n",
       "      <td>298.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-05 11:15:00</td>\n",
       "      <td>9041.88</td>\n",
       "      <td>9041.88</td>\n",
       "      <td>9039.00</td>\n",
       "      <td>9039.99</td>\n",
       "      <td>68.817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-05 11:20:00</td>\n",
       "      <td>9039.99</td>\n",
       "      <td>9042.87</td>\n",
       "      <td>9039.88</td>\n",
       "      <td>9042.05</td>\n",
       "      <td>106.649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-05 11:25:00</td>\n",
       "      <td>9042.05</td>\n",
       "      <td>9046.52</td>\n",
       "      <td>9041.24</td>\n",
       "      <td>9045.70</td>\n",
       "      <td>385.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-05 11:30:00</td>\n",
       "      <td>9045.69</td>\n",
       "      <td>9045.99</td>\n",
       "      <td>9040.00</td>\n",
       "      <td>9041.19</td>\n",
       "      <td>111.229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     open     high      low    close   volume\n",
       "0 2020-07-05 11:10:00  9042.40  9044.94  9036.61  9041.88  298.229\n",
       "1 2020-07-05 11:15:00  9041.88  9041.88  9039.00  9039.99   68.817\n",
       "2 2020-07-05 11:20:00  9039.99  9042.87  9039.88  9042.05  106.649\n",
       "3 2020-07-05 11:25:00  9042.05  9046.52  9041.24  9045.70  385.077\n",
       "4 2020-07-05 11:30:00  9045.69  9045.99  9040.00  9041.19  111.229"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "# 1. Point to your data folder\n",
    "data_dir = \"/Users/harit/algo_crypto/mymodules/data\"\n",
    "\n",
    "# 2. Find all CSV files\n",
    "csv_paths = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
    "\n",
    "# 3. Load into a dict of DataFrames, converting the millisecond timestamp\n",
    "dfs = {}\n",
    "for path in csv_paths:\n",
    "    name = os.path.splitext(os.path.basename(path))[0]\n",
    "    df = pd.read_csv(path)  \n",
    "    # Convert the UNIX-ms timestamp to a true datetime\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    # (optional) drop the raw timestamp column\n",
    "    df.drop(columns=['timestamp'], inplace=True)\n",
    "    # Reorder so datetime is first\n",
    "    cols = ['datetime', 'open', 'high', 'low', 'close', 'volume']\n",
    "    df = df[cols]\n",
    "    dfs[name] = df\n",
    "\n",
    "# 4. Peek at one\n",
    "sample_key = 'BTCUSDT_5m_5year'\n",
    "print(\"Loaded keys:\", list(dfs.keys()))\n",
    "print(f\"\\nSample head for {sample_key}:\")\n",
    "display(dfs[sample_key].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c64b67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded: ['BTCUSDT_1h_5year', 'ETHUSDT_1m_5year', 'BTCUSDT_5m_5year', 'BTCUSDT_15m_5year', 'ETHUSDT_1h_5year', 'BTCUSDT_1m_5year', 'ETHUSDT_5m_5year', 'ETHUSDT_15m_5year']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob, os\n",
    "\n",
    "# Reload the raw CSVs into dfs\n",
    "data_dir = \"/Users/harit/algo_crypto/mymodules/data\"\n",
    "csv_paths = glob.glob(os.path.join(data_dir, \"*.csv\"))\n",
    "\n",
    "dfs = {}\n",
    "for path in csv_paths:\n",
    "    name = os.path.splitext(os.path.basename(path))[0]\n",
    "    df = pd.read_csv(path)\n",
    "    df['datetime'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    df.drop(columns=['timestamp'], inplace=True)\n",
    "    df = df[['datetime','open','high','low','close','volume']]\n",
    "    dfs[name] = df\n",
    "\n",
    "print(\"Datasets loaded:\", list(dfs.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e89de62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic regime threshold (90th pct): 1.380\n",
      "Normal regime size: (473044, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>atr_ratio</th>\n",
       "      <th>high_vol_regime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-05 11:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-05 11:15:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-05 11:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-05 11:25:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-05 11:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  atr_ratio  high_vol_regime\n",
       "0 2020-07-05 11:10:00        NaN                0\n",
       "1 2020-07-05 11:15:00        NaN                0\n",
       "2 2020-07-05 11:20:00        NaN                0\n",
       "3 2020-07-05 11:25:00        NaN                0\n",
       "4 2020-07-05 11:30:00        NaN                0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tail regime size: (52556, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>atr_ratio</th>\n",
       "      <th>high_vol_regime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>2020-07-05 21:00:00</td>\n",
       "      <td>1.394751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2020-07-05 21:05:00</td>\n",
       "      <td>1.402807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2020-07-05 21:15:00</td>\n",
       "      <td>2.582428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2020-07-05 21:20:00</td>\n",
       "      <td>2.654296</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2020-07-05 21:25:00</td>\n",
       "      <td>2.674493</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               datetime  atr_ratio  high_vol_regime\n",
       "118 2020-07-05 21:00:00   1.394751                1\n",
       "119 2020-07-05 21:05:00   1.402807                1\n",
       "121 2020-07-05 21:15:00   2.582428                1\n",
       "122 2020-07-05 21:20:00   2.654296                1\n",
       "123 2020-07-05 21:25:00   2.674493                1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "# 1) Extract & sort the BTCUSDT 5 m DataFrame\n",
    "df5 = dfs['BTCUSDT_5m_5year'].sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "# 2) Compute ATR & ATR ratio\n",
    "ATR_WINDOW = 14\n",
    "tr = pd.concat([\n",
    "    df5['high'] - df5['low'],\n",
    "    (df5['high'] - df5['close'].shift(1)).abs(),\n",
    "    (df5['low']  - df5['close'].shift(1)).abs()\n",
    "], axis=1).max(axis=1)\n",
    "df5['atr']       = tr.rolling(ATR_WINDOW).mean()\n",
    "df5['atr_slow']  = df5['atr'].rolling(ATR_WINDOW*2).mean()\n",
    "df5['atr_ratio'] = df5['atr'] / df5['atr_slow']\n",
    "\n",
    "# 3) Dynamic regime threshold (90th percentile)\n",
    "threshold = df5['atr_ratio'].quantile(0.90)\n",
    "df5['high_vol_regime'] = (df5['atr_ratio'] > threshold).astype(int)\n",
    "print(f\"Dynamic regime threshold (90th pct): {threshold:.3f}\")\n",
    "\n",
    "# 4) Split into “normal” vs “tail” subsets\n",
    "normal_df = df5[df5['high_vol_regime']==0].copy()\n",
    "tail_df   = df5[df5['high_vol_regime']==1].copy()\n",
    "\n",
    "# 5) Inspect the separation\n",
    "print(\"Normal regime size:\", normal_df.shape)\n",
    "display(normal_df[['datetime','atr_ratio','high_vol_regime']].head())\n",
    "\n",
    "print(\"Tail regime size:\", tail_df.shape)\n",
    "display(tail_df[['datetime','atr_ratio','high_vol_regime']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b9392c",
   "metadata": {},
   "source": [
    "## PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7defbc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your specific keys here:\n",
    "key_5m = 'BTCUSDT_5m_5year'\n",
    "key_1h = 'BTCUSDT_1h_5year'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bebea66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic regime threshold (90th pct of ATR ratio): 1.38\n",
      "Normal regime size: (472528, 19)\n",
      "Tail   regime size: (52527, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>atr</th>\n",
       "      <th>atr_slow</th>\n",
       "      <th>atr_ratio</th>\n",
       "      <th>rsi</th>\n",
       "      <th>ema_long</th>\n",
       "      <th>adx</th>\n",
       "      <th>vol_ma</th>\n",
       "      <th>vwap</th>\n",
       "      <th>vwap_upper</th>\n",
       "      <th>vwap_lower</th>\n",
       "      <th>ema_hf</th>\n",
       "      <th>return_next</th>\n",
       "      <th>high_vol_regime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-05 14:30:00</td>\n",
       "      <td>9025.28</td>\n",
       "      <td>9025.28</td>\n",
       "      <td>9018.00</td>\n",
       "      <td>9019.90</td>\n",
       "      <td>160.300</td>\n",
       "      <td>10.754286</td>\n",
       "      <td>11.424949</td>\n",
       "      <td>0.941298</td>\n",
       "      <td>48.813696</td>\n",
       "      <td>9030.389199</td>\n",
       "      <td>2.304033</td>\n",
       "      <td>437.42675</td>\n",
       "      <td>9026.939910</td>\n",
       "      <td>9035.966850</td>\n",
       "      <td>9017.912970</td>\n",
       "      <td>9015.688235</td>\n",
       "      <td>-0.000265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-05 14:35:00</td>\n",
       "      <td>9019.91</td>\n",
       "      <td>9025.00</td>\n",
       "      <td>9019.91</td>\n",
       "      <td>9022.89</td>\n",
       "      <td>177.250</td>\n",
       "      <td>10.142143</td>\n",
       "      <td>11.461786</td>\n",
       "      <td>0.884866</td>\n",
       "      <td>40.214140</td>\n",
       "      <td>9030.095113</td>\n",
       "      <td>10.453127</td>\n",
       "      <td>436.10000</td>\n",
       "      <td>9026.896435</td>\n",
       "      <td>9035.923331</td>\n",
       "      <td>9017.869539</td>\n",
       "      <td>9015.688235</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-05 14:40:00</td>\n",
       "      <td>9022.89</td>\n",
       "      <td>9033.00</td>\n",
       "      <td>9022.89</td>\n",
       "      <td>9027.48</td>\n",
       "      <td>415.129</td>\n",
       "      <td>10.453571</td>\n",
       "      <td>11.508291</td>\n",
       "      <td>0.908351</td>\n",
       "      <td>44.380616</td>\n",
       "      <td>9029.992560</td>\n",
       "      <td>3.426990</td>\n",
       "      <td>423.12500</td>\n",
       "      <td>9026.916919</td>\n",
       "      <td>9035.943836</td>\n",
       "      <td>9017.890002</td>\n",
       "      <td>9015.688235</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     open     high      low    close   volume        atr  \\\n",
       "0 2020-07-05 14:30:00  9025.28  9025.28  9018.00  9019.90  160.300  10.754286   \n",
       "1 2020-07-05 14:35:00  9019.91  9025.00  9019.91  9022.89  177.250  10.142143   \n",
       "2 2020-07-05 14:40:00  9022.89  9033.00  9022.89  9027.48  415.129  10.453571   \n",
       "\n",
       "    atr_slow  atr_ratio        rsi     ema_long        adx     vol_ma  \\\n",
       "0  11.424949   0.941298  48.813696  9030.389199   2.304033  437.42675   \n",
       "1  11.461786   0.884866  40.214140  9030.095113  10.453127  436.10000   \n",
       "2  11.508291   0.908351  44.380616  9029.992560   3.426990  423.12500   \n",
       "\n",
       "          vwap   vwap_upper   vwap_lower       ema_hf  return_next  \\\n",
       "0  9026.939910  9035.966850  9017.912970  9015.688235    -0.000265   \n",
       "1  9026.896435  9035.923331  9017.869539  9015.688235     0.000839   \n",
       "2  9026.916919  9035.943836  9017.890002  9015.688235     0.000459   \n",
       "\n",
       "   high_vol_regime  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>atr</th>\n",
       "      <th>atr_slow</th>\n",
       "      <th>atr_ratio</th>\n",
       "      <th>rsi</th>\n",
       "      <th>ema_long</th>\n",
       "      <th>adx</th>\n",
       "      <th>vol_ma</th>\n",
       "      <th>vwap</th>\n",
       "      <th>vwap_upper</th>\n",
       "      <th>vwap_lower</th>\n",
       "      <th>ema_hf</th>\n",
       "      <th>return_next</th>\n",
       "      <th>high_vol_regime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>2020-07-05 21:00:00</td>\n",
       "      <td>9013.44</td>\n",
       "      <td>9019.00</td>\n",
       "      <td>9003.06</td>\n",
       "      <td>9019.00</td>\n",
       "      <td>1011.406</td>\n",
       "      <td>6.975000</td>\n",
       "      <td>5.000893</td>\n",
       "      <td>1.394751</td>\n",
       "      <td>33.951987</td>\n",
       "      <td>9033.242773</td>\n",
       "      <td>52.970394</td>\n",
       "      <td>231.47660</td>\n",
       "      <td>9032.657122</td>\n",
       "      <td>9041.689779</td>\n",
       "      <td>9023.624464</td>\n",
       "      <td>9019.165771</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>2020-07-05 21:05:00</td>\n",
       "      <td>9019.00</td>\n",
       "      <td>9020.00</td>\n",
       "      <td>9012.18</td>\n",
       "      <td>9013.16</td>\n",
       "      <td>361.556</td>\n",
       "      <td>7.193571</td>\n",
       "      <td>5.127985</td>\n",
       "      <td>1.402807</td>\n",
       "      <td>32.484076</td>\n",
       "      <td>9032.455213</td>\n",
       "      <td>59.530042</td>\n",
       "      <td>245.65630</td>\n",
       "      <td>9032.491374</td>\n",
       "      <td>9041.523866</td>\n",
       "      <td>9023.458883</td>\n",
       "      <td>9019.165771</td>\n",
       "      <td>-0.001206</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>2020-07-05 21:15:00</td>\n",
       "      <td>9008.12</td>\n",
       "      <td>9008.74</td>\n",
       "      <td>8900.00</td>\n",
       "      <td>8959.13</td>\n",
       "      <td>10688.672</td>\n",
       "      <td>14.531429</td>\n",
       "      <td>5.627041</td>\n",
       "      <td>2.582428</td>\n",
       "      <td>16.508092</td>\n",
       "      <td>9028.662817</td>\n",
       "      <td>63.160872</td>\n",
       "      <td>765.41325</td>\n",
       "      <td>9015.757709</td>\n",
       "      <td>9024.773467</td>\n",
       "      <td>9006.741951</td>\n",
       "      <td>9019.165771</td>\n",
       "      <td>-0.005564</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime     open     high      low    close     volume  \\\n",
       "78 2020-07-05 21:00:00  9013.44  9019.00  9003.06  9019.00   1011.406   \n",
       "79 2020-07-05 21:05:00  9019.00  9020.00  9012.18  9013.16    361.556   \n",
       "81 2020-07-05 21:15:00  9008.12  9008.74  8900.00  8959.13  10688.672   \n",
       "\n",
       "          atr  atr_slow  atr_ratio        rsi     ema_long        adx  \\\n",
       "78   6.975000  5.000893   1.394751  33.951987  9033.242773  52.970394   \n",
       "79   7.193571  5.127985   1.402807  32.484076  9032.455213  59.530042   \n",
       "81  14.531429  5.627041   2.582428  16.508092  9028.662817  63.160872   \n",
       "\n",
       "       vol_ma         vwap   vwap_upper   vwap_lower       ema_hf  \\\n",
       "78  231.47660  9032.657122  9041.689779  9023.624464  9019.165771   \n",
       "79  245.65630  9032.491374  9041.523866  9023.458883  9019.165771   \n",
       "81  765.41325  9015.757709  9024.773467  9006.741951  9019.165771   \n",
       "\n",
       "    return_next  high_vol_regime  \n",
       "78    -0.000031                1  \n",
       "79    -0.001206                1  \n",
       "81    -0.005564                1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ── Full Feature Engineering & Regime Separation ────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "LOOKBACK      = 20\n",
    "ATR_WINDOW    = 14\n",
    "EMA_LONG      = 50\n",
    "ADX_WINDOW    = 14\n",
    "VWAP_BAND_PCT = 0.001  # ±0.1%\n",
    "\n",
    "# 1) Extract & sort your loaded DataFrames\n",
    "df5  = dfs['BTCUSDT_5m_5year'].sort_values('datetime').reset_index(drop=True)\n",
    "df1h = dfs['BTCUSDT_1h_5year'].sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "# 2) Precompute 1h EMA\n",
    "df1h['ema_hf'] = df1h['close'].ewm(span=EMA_LONG, adjust=False).mean()\n",
    "df1h_hf = df1h[['datetime','ema_hf']]\n",
    "\n",
    "# 3) Build 5m features\n",
    "df = df5.copy()\n",
    "df['prev_close'] = df['close'].shift(1)\n",
    "\n",
    "# 3a) ATR & ATR ratio\n",
    "tr = pd.concat([\n",
    "    df['high'] - df['low'],\n",
    "    (df['high'] - df['prev_close']).abs(),\n",
    "    (df['low']  - df['prev_close']).abs()\n",
    "], axis=1).max(axis=1)\n",
    "df['atr']       = tr.rolling(ATR_WINDOW).mean()\n",
    "df['atr_slow']  = df['atr'].rolling(ATR_WINDOW*2).mean()\n",
    "df['atr_ratio'] = df['atr'] / df['atr_slow']\n",
    "\n",
    "# 3b) RSI(14)\n",
    "delta = df['close'].diff()\n",
    "up, down = delta.clip(lower=0), -delta.clip(upper=0)\n",
    "df['rsi'] = 100 - 100/(1 + up.rolling(ATR_WINDOW).mean()/down.rolling(ATR_WINDOW).mean())\n",
    "\n",
    "# 3c) EMA long on 5m\n",
    "df['ema_long'] = df['close'].ewm(span=EMA_LONG, adjust=False).mean()\n",
    "\n",
    "# 3d) ADX(14)\n",
    "up_m   = df['high'].diff()\n",
    "down_m = -(df['low'].shift(1).diff())\n",
    "plus   = np.where((up_m>down_m)&(up_m>0), up_m, 0.0)\n",
    "minus  = np.where((down_m>up_m)&(down_m>0), down_m, 0.0)\n",
    "sm_tr  = tr.ewm(alpha=1/ADX_WINDOW, adjust=False).mean()\n",
    "sm_p   = pd.Series(plus).ewm(alpha=1/ADX_WINDOW, adjust=False).mean()\n",
    "sm_m   = pd.Series(minus).ewm(alpha=1/ADX_WINDOW, adjust=False).mean()\n",
    "df['adx'] = 100 * (sm_p - sm_m).abs()/(sm_p + sm_m)\n",
    "\n",
    "# 3e) Volume MA\n",
    "df['vol_ma'] = df['volume'].rolling(20).mean()\n",
    "\n",
    "# 3f) VWAP bands\n",
    "df['date']     = df['datetime'].dt.date\n",
    "typ           = (df['high'] + df['low'] + df['close'])/3\n",
    "df['cum_vp']   = typ.mul(df['volume']).groupby(df['date']).cumsum()\n",
    "df['cum_vol']  = df['volume'].groupby(df['date']).cumsum()\n",
    "df['vwap']     = df['cum_vp'] / df['cum_vol']\n",
    "df['vwap_upper'] = df['vwap'] * (1 + VWAP_BAND_PCT)\n",
    "df['vwap_lower'] = df['vwap'] * (1 - VWAP_BAND_PCT)\n",
    "\n",
    "# 3g) Merge 1h EMA into 5m\n",
    "df['hour'] = df['datetime'].dt.floor('h')\n",
    "df = df.merge(df1h_hf.rename(columns={'datetime':'hour'}), on='hour', how='left')\n",
    "\n",
    "# 4) Define the target\n",
    "df['return_next'] = df['close'].shift(-1) / df['open'] - 1\n",
    "\n",
    "# 5) Dynamic regime flag (90th percentile of atr_ratio)\n",
    "threshold = df['atr_ratio'].quantile(0.90)\n",
    "df['high_vol_regime'] = (df['atr_ratio'] > threshold).astype(int)\n",
    "print(f\"Dynamic regime threshold (90th pct of ATR ratio): {threshold:.2f}\")\n",
    "\n",
    "# 6) Clean up and build final df_feat\n",
    "df_feat = (\n",
    "    df.drop(columns=['prev_close','date','cum_vp','cum_vol','hour'])\n",
    "      .dropna()\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# 7) Split into Normal vs. Tail regimes\n",
    "normal_df = df_feat[df_feat['high_vol_regime']==0].copy()\n",
    "tail_df   = df_feat[df_feat['high_vol_regime']==1].copy()\n",
    "\n",
    "# 8) Inspect the separation\n",
    "print(\"Normal regime size:\", normal_df.shape)\n",
    "print(\"Tail   regime size:\", tail_df.shape)\n",
    "display(normal_df.head(3), tail_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5eb76c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Expert → Train: (378022, 9), Test: (94506, 9)\n",
      "Normal Expert → MSE: 0.000004, R²: 0.0357\n",
      "Tail Expert   → Train: (42021, 9), Test: (10506, 9)\n",
      "Tail Expert   → MSE: 0.000014, R²: -0.0092\n",
      "Classifier Accuracy: 1.0000\n",
      "Mixture‐of‐Experts → MSE: 0.000005, R²: 0.0229\n"
     ]
    }
   ],
   "source": [
    "# ── 2) Preprocess, train experts, and fit regime classifier ───────────────────\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Feature and target names\n",
    "feature_cols = ['atr','atr_ratio','rsi','ema_long','ema_hf','adx','vol_ma','vwap_upper','vwap_lower']\n",
    "target_col   = 'return_next'\n",
    "\n",
    "# --- 2.1) Normal‐regime expert ---\n",
    "Xn = normal_df[feature_cols]\n",
    "yn = normal_df[target_col]\n",
    "Xn_tr, Xn_te, yn_tr, yn_te = train_test_split(Xn, yn, test_size=0.2, shuffle=False)\n",
    "print(f\"Normal Expert → Train: {Xn_tr.shape}, Test: {Xn_te.shape}\")\n",
    "\n",
    "model_norm = HistGradientBoostingRegressor(random_state=42)\n",
    "model_norm.fit(Xn_tr, yn_tr)\n",
    "\n",
    "pred_n = model_norm.predict(Xn_te)\n",
    "print(f\"Normal Expert → MSE: {mean_squared_error(yn_te,pred_n):.6f}, R²: {r2_score(yn_te,pred_n):.4f}\")\n",
    "\n",
    "# --- 2.2) Tail‐regime expert ---\n",
    "Xt = tail_df[feature_cols]\n",
    "yt = tail_df[target_col]\n",
    "Xt_tr, Xt_te, yt_tr, yt_te = train_test_split(Xt, yt, test_size=0.2, shuffle=False)\n",
    "print(f\"Tail Expert   → Train: {Xt_tr.shape}, Test: {Xt_te.shape}\")\n",
    "\n",
    "model_tail = HistGradientBoostingRegressor(random_state=42)\n",
    "model_tail.fit(Xt_tr, yt_tr)\n",
    "\n",
    "pred_t = model_tail.predict(Xt_te)\n",
    "print(f\"Tail Expert   → MSE: {mean_squared_error(yt_te,pred_t):.6f}, R²: {r2_score(yt_te,pred_t):.4f}\")\n",
    "\n",
    "# --- 2.3) Regime classifier ---\n",
    "Xc = df_feat[feature_cols]\n",
    "yc = df_feat['high_vol_regime']\n",
    "Xc_tr, Xc_te, yc_tr, yc_te = train_test_split(Xc, yc, test_size=0.2, shuffle=False)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(Xc_tr, yc_tr)\n",
    "print(f\"Classifier Accuracy: {clf.score(Xc_te, yc_te):.4f}\")\n",
    "\n",
    "# --- 2.4) Mixture‐of‐Experts hold‐out evaluation ---\n",
    "X_hold = pd.concat([Xn_te, Xt_te])\n",
    "y_hold = pd.concat([yn_te, yt_te])\n",
    "reg_pred = clf.predict(X_hold)\n",
    "\n",
    "y_pred = np.where(\n",
    "    reg_pred == 0,\n",
    "    model_norm.predict(X_hold),\n",
    "    model_tail.predict(X_hold)\n",
    ")\n",
    "\n",
    "print(f\"Mixture‐of‐Experts → MSE: {mean_squared_error(y_hold,y_pred):.6f}, R²: {r2_score(y_hold,y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ed3486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tail XGB → MSE: 1.8527237734442637e-05 R²: -0.3171141063423033\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "tail_xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "tail_xgb.fit(Xt_tr, yt_tr)\n",
    "pred_tx = tail_xgb.predict(Xt_te)\n",
    "print(\"Tail XGB → MSE:\", mean_squared_error(yt_te,pred_tx),\n",
    "      \"R²:\", r2_score(yt_te,pred_tx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bfb35f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=3, n_estimators=200, reg_alpha=1.0, reg_lambda=5.0, subsample=0.5; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=3, n_estimators=200, reg_alpha=1.0, reg_lambda=5.0, subsample=0.5; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=1.0, subsample=0.9; total time=   0.0s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=3, n_estimators=200, reg_alpha=1.0, reg_lambda=5.0, subsample=0.5; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=1.0, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=1.0, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=3, n_estimators=200, reg_alpha=1.0, reg_lambda=5.0, subsample=0.5; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=3, n_estimators=100, reg_alpha=0.1, reg_lambda=1.0, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.03, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.03, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.5; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.03, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.5; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.03, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=0.9; total time=   1.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.5; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=15, n_estimators=100, reg_alpha=0, reg_lambda=2.0, subsample=1.0; total time=   1.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=10, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.5; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=0.9; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=15, n_estimators=100, reg_alpha=0, reg_lambda=2.0, subsample=1.0; total time=   2.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=0.9; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, reg_alpha=0.5, reg_lambda=1.0, subsample=0.7; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, reg_alpha=0.5, reg_lambda=1.0, subsample=0.7; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, reg_alpha=0.5, reg_lambda=1.0, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=15, n_estimators=100, reg_alpha=0, reg_lambda=2.0, subsample=1.0; total time=   2.8s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=0.9; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, reg_alpha=0.5, reg_lambda=5.0, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=3, n_estimators=300, reg_alpha=0.5, reg_lambda=1.0, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, reg_alpha=0.5, reg_lambda=5.0, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=15, n_estimators=100, reg_alpha=0, reg_lambda=2.0, subsample=1.0; total time=   3.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, reg_alpha=0.5, reg_lambda=5.0, subsample=0.9; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=0.9; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.01, max_depth=10, n_estimators=200, reg_alpha=0.5, reg_lambda=5.0, subsample=0.9; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, reg_alpha=0, reg_lambda=2.0, subsample=0.5; total time=   3.0s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=5.0, subsample=0.5; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=5.0, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=15, n_estimators=100, reg_alpha=0.5, reg_lambda=5.0, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=5.0, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.1, reg_lambda=5.0, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=15, n_estimators=100, reg_alpha=0.5, reg_lambda=5.0, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=15, n_estimators=100, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   1.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=15, n_estimators=100, reg_alpha=0.5, reg_lambda=5.0, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=15, n_estimators=100, reg_alpha=0.5, reg_lambda=5.0, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, reg_alpha=0, reg_lambda=2.0, subsample=0.5; total time=   3.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=15, n_estimators=100, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   2.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=1.0; total time=   0.7s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, reg_alpha=0, reg_lambda=2.0, subsample=0.5; total time=   4.6s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=500, reg_alpha=0.1, reg_lambda=5.0, subsample=1.0; total time=   0.9s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=10, n_estimators=500, reg_alpha=0, reg_lambda=2.0, subsample=0.5; total time=   4.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, reg_alpha=0, reg_lambda=2.0, subsample=0.7; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=2.0, subsample=0.9; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.0, subsample=0.7; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.0, subsample=0.7; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.0, subsample=0.7; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, reg_alpha=0, reg_lambda=2.0, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=15, n_estimators=100, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=3, n_estimators=100, reg_alpha=0, reg_lambda=1.0, subsample=0.7; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, reg_alpha=0, reg_lambda=2.0, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=15, n_estimators=100, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   3.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, reg_alpha=0, reg_lambda=2.0, subsample=0.7; total time=   0.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harit/algo_crypto/myvenv/lib/python3.12/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.9, learning_rate=0.03, max_depth=3, n_estimators=100, reg_alpha=1.0, reg_lambda=1.0, subsample=0.7; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=2.0, subsample=0.9; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.03, max_depth=3, n_estimators=100, reg_alpha=1.0, reg_lambda=1.0, subsample=0.7; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.03, max_depth=3, n_estimators=100, reg_alpha=1.0, reg_lambda=1.0, subsample=0.7; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.03, max_depth=3, n_estimators=100, reg_alpha=1.0, reg_lambda=1.0, subsample=0.7; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.03, max_depth=15, n_estimators=100, reg_alpha=0.1, reg_lambda=5.0, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.5, reg_lambda=5.0, subsample=0.7; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.5, reg_lambda=5.0, subsample=0.7; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=15, n_estimators=300, reg_alpha=0.5, reg_lambda=2.0, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=2.0, subsample=0.9; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=15, n_estimators=300, reg_alpha=0.5, reg_lambda=2.0, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.03, max_depth=15, n_estimators=100, reg_alpha=0.1, reg_lambda=5.0, subsample=1.0; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.05, max_depth=15, n_estimators=200, reg_alpha=0.1, reg_lambda=2.0, subsample=0.9; total time=   2.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=15, n_estimators=300, reg_alpha=0.5, reg_lambda=2.0, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.03, max_depth=15, n_estimators=100, reg_alpha=0.1, reg_lambda=5.0, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=15, n_estimators=300, reg_alpha=0.5, reg_lambda=2.0, subsample=1.0; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=1.0, reg_lambda=1.0, subsample=0.5; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.03, max_depth=15, n_estimators=100, reg_alpha=0.1, reg_lambda=5.0, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=10, n_estimators=100, reg_alpha=0.5, reg_lambda=5.0, subsample=0.5; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=1.0, reg_lambda=1.0, subsample=0.5; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=10, n_estimators=100, reg_alpha=0.5, reg_lambda=5.0, subsample=0.5; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=10, n_estimators=100, reg_alpha=0.5, reg_lambda=5.0, subsample=0.5; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=10, n_estimators=200, reg_alpha=0, reg_lambda=5.0, subsample=1.0; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=1.0, reg_lambda=1.0, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.5, reg_lambda=5.0, subsample=0.7; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.03, max_depth=10, n_estimators=100, reg_alpha=0.5, reg_lambda=5.0, subsample=0.5; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=15, n_estimators=300, reg_alpha=1.0, reg_lambda=2.0, subsample=1.0; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=15, n_estimators=300, reg_alpha=1.0, reg_lambda=2.0, subsample=1.0; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1.0, subsample=0.7; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=15, n_estimators=300, reg_alpha=1.0, reg_lambda=2.0, subsample=1.0; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.5, learning_rate=0.1, max_depth=3, n_estimators=300, reg_alpha=0.5, reg_lambda=5.0, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1.0, subsample=0.7; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=10, n_estimators=200, reg_alpha=0, reg_lambda=5.0, subsample=1.0; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.03, max_depth=15, n_estimators=300, reg_alpha=1.0, reg_lambda=2.0, subsample=1.0; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=10, n_estimators=200, reg_alpha=0, reg_lambda=5.0, subsample=1.0; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1.0, subsample=0.7; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.5; total time=   0.4s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.05, max_depth=10, n_estimators=200, reg_alpha=0, reg_lambda=5.0, subsample=1.0; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.7, learning_rate=0.01, max_depth=6, n_estimators=300, reg_alpha=0.5, reg_lambda=1.0, subsample=0.7; total time=   0.6s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=0.1, reg_lambda=1.0, subsample=0.5; total time=   0.5s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0.5, reg_lambda=1.0, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0.5, reg_lambda=1.0, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0.5, reg_lambda=1.0, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.01, max_depth=6, n_estimators=200, reg_alpha=1.0, reg_lambda=1.0, subsample=0.5; total time=   0.3s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=500, reg_alpha=0, reg_lambda=5.0, subsample=0.5; total time=   0.7s\n",
      "[CV] END colsample_bytree=0.9, learning_rate=0.1, max_depth=6, n_estimators=100, reg_alpha=0.5, reg_lambda=1.0, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   0.1s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.01, max_depth=3, n_estimators=200, reg_alpha=0, reg_lambda=5.0, subsample=0.9; total time=   0.2s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=500, reg_alpha=0, reg_lambda=5.0, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=500, reg_alpha=0, reg_lambda=5.0, subsample=0.5; total time=   0.8s\n",
      "[CV] END colsample_bytree=1.0, learning_rate=0.05, max_depth=6, n_estimators=500, reg_alpha=0, reg_lambda=5.0, subsample=0.5; total time=   0.9s\n",
      "Best Tail-Expert Params: {'subsample': 0.5, 'reg_lambda': 1.0, 'reg_alpha': 0.1, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.01, 'colsample_bytree': 0.9}\n",
      "Best CV MSE: 1.5611148522890035e-05\n",
      "Tail-XGB Hold-out → MSE: 1.3510408224383367e-05 R²: 0.03953576297574668\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "# 1) Prepare tail subset\n",
    "feature_cols = ['atr','atr_ratio','rsi','ema_long','ema_hf','adx','vol_ma','vwap_upper','vwap_lower']\n",
    "Xt = tail_df[feature_cols]\n",
    "yt = tail_df['return_next']\n",
    "\n",
    "# 2) Train/test split (chronological)\n",
    "split = int(len(Xt) * 0.8)\n",
    "Xt_tr, Xt_te = Xt.iloc[:split], Xt.iloc[split:]\n",
    "yt_tr, yt_te = yt.iloc[:split], yt.iloc[split:]\n",
    "\n",
    "# 3) Define XGB param space\n",
    "xgb_param_dist = {\n",
    "    'n_estimators':    [100, 200, 300, 500],\n",
    "    'max_depth':       [3, 6, 10, 15],\n",
    "    'learning_rate':   [0.01, 0.03, 0.05, 0.1],\n",
    "    'subsample':       [0.5, 0.7, 0.9, 1.0],\n",
    "    'colsample_bytree':[0.5, 0.7, 0.9, 1.0],\n",
    "    'reg_alpha':       [0, 0.1, 0.5, 1.0],\n",
    "    'reg_lambda':      [1.0, 2.0, 5.0]\n",
    "}\n",
    "\n",
    "# 4) TimeSeriesSplit & scorer\n",
    "tscv      = TimeSeriesSplit(n_splits=4)\n",
    "mse_scorer= make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# 5) RandomizedSearchCV\n",
    "search = RandomizedSearchCV(\n",
    "    XGBRegressor(objective='reg:squarederror', random_state=42, n_jobs=-1),\n",
    "    xgb_param_dist,\n",
    "    n_iter=30,\n",
    "    scoring=mse_scorer,\n",
    "    cv=tscv,\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "search.fit(Xt_tr, yt_tr)\n",
    "\n",
    "# 6) Best tail-expert params & CV MSE\n",
    "print(\"Best Tail-Expert Params:\", search.best_params_)\n",
    "print(\"Best CV MSE:\", -search.best_score_)\n",
    "\n",
    "# 7) Evaluate on hold-out\n",
    "best_tail = search.best_estimator_\n",
    "pred_tail = best_tail.predict(Xt_te)\n",
    "print(\"Tail-XGB Hold-out → MSE:\",\n",
    "      mean_squared_error(yt_te, pred_tail),\n",
    "      \"R²:\", r2_score(yt_te, pred_tail))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be0083b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Ensemble → MSE: 0.000005, R²: 0.0368\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# 3.1) Rename for clarity\n",
    "tail_xgb = search.best_estimator_\n",
    "norm_hgb = model_norm  # from your normal-expert cell\n",
    "clf_rf   = clf         # your regime classifier\n",
    "\n",
    "# 3.2) Build hold-out set\n",
    "X_hold = pd.concat([Xn_te, Xt_te])\n",
    "y_hold = pd.concat([yn_te, yt_te])\n",
    "\n",
    "# 3.3) Classify regimes and predict\n",
    "regime_pred = clf_rf.predict(X_hold)\n",
    "pred_norm   = norm_hgb.predict(X_hold)\n",
    "pred_tail   = tail_xgb.predict(X_hold)\n",
    "\n",
    "# 3.4) Mixture (hard switch)\n",
    "y_pred_mix  = np.where(regime_pred==0, pred_norm, pred_tail)\n",
    "\n",
    "# 3.5) Evaluate\n",
    "mse_mix = mean_squared_error(y_hold, y_pred_mix)\n",
    "r2_mix  = r2_score(y_hold, y_pred_mix)\n",
    "print(f\"Updated Ensemble → MSE: {mse_mix:.6f}, R²: {r2_mix:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b6e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
